
\section{Appendix}

\subsection{Weights for soft constrains}
\label{sec:weights}

Next, we describe a method for assigning weights to soft constraints $Q$ using SBERT Retrieval and  Natural Language Inference (NLI) Reranking. The weight \(w(Q)\in(0,1)\) that reflects how strongly the document supports \(Q\) versus contradicts \(Q\). It uses the following tools:
\begin{itemize}
\item \textbf {A bi-encoder} sentence embedding model (e.g., SBERT) for fast retrieval of relevant segments.
\item \textbf{An NLI cross-encoder} (Natural Language Inference) to score entailment vs contradiction on only a small set of retrieved segments.
\item \textbf{Log-sum-exp pooling} to aggregate evidence robustly (less brittle than max pooling).
\item \textbf{A final sigmoid} transform to map pooled evidence to a probability-like weight.
\end{itemize}
The resulting weight is an evidence score, not a statistically calibrated probability. It is obtained from the following algorithm
\begin{itemize}
    \item[1.]
    Given a soft constraint $Q$ from  a natural-language hypothesis sentence $h$.
We can generate a small set of paraphrases (phrases with the same meaning)
\[
\mathcal{H}(Q) = \{h_1,\dots,h_r\},
\]
where $r\in[1,10]$. These paraphrases improve recall; and they are optional.
\item[2.] Let $e(\cdot)$ be the SBERT embedding function. We precompute embeddings for all segments:
\[
v_i = e(s_i)\quad\text{for } i=1,\dots,m.
\]

For each hypothesis $h_j$, compute its embedding $u_j = e(h_j)$ and retrieve the top-$K$ segments by cosine similarity:
\[
E_j = \text{TopK}_{s_i\in S(T)} \cos(u_j, v_i).
\]
Then form the union of retrieved candidates and deduplicate:
\[
E = \bigcup_{j=1}^r E_j,
\]
optionally truncating to a maximum total budget $K_{\text{total}}$ (e.g., 50) by keeping the highest-similarity unique segments.
\item For each candidate premise segment $p \in E$ and hypothesis $h_j \in \mathcal{H}(Q)$, run an NLI cross-encoder:
\[
(z_{\text{ent}}(p,h_j), z_{\text{con}}(p,h_j), z_{\text{neu}}(p,h_j)) \in \mathbb{R}^3.
\]

Here: $z_{\text{ent}}$ is the entailment logit score.  $z_{\text{con}}$ is the contradiction logit score.  $z_{\text{neu}}$ is the neutral logit score.
\item We reduce the 3-way output to a single scalar \textbf{evidence difference}:
\[
d(p,h_j) := z_{\text{ent}}(p,h_j) - z_{\text{con}}(p,h_j).
\]
This last choice improve stability of the results, and it has the  interpretation:
\begin{itemize}
    \item $d(p,h_j) > 0$: this segment supports the constraint.
    \item $d(p,h_j) < 0$: this segment contradicts the constraint.
    \item $|d|$: strength of evidence.
\end{itemize}
For each premise segment $p$, keep the best paraphrase match:
\[
d(p) := \max_{h_j \in \mathcal{H}(Q)} d(p,h_j).
\]
This yields a set of evidence scores $\{d(p): p\in E\}$.
\item A naive max over $d(p)$ is brittle (one spurious segment can dominate). We instead use \textbf{log-sum-exp pooling}, which is a smooth approximation of max.
Let $E=\{p_1,\dots,p_K\}$ after deduplication/truncation. Define:
\[
D(Q;T) \;:=\; \frac{1}{\tau}\log\left(\frac{1}{K}\sum_{i=1}^{K} \exp(\tau\, d(p_i))\right),
\]
where $\tau>0$ is a temperature parameter controlling how ``max-like'' the pooling is:
\begin{itemize}
    \item small $\tau \to$ closer to an average,
    \item large $\tau \to$ closer to a max.
\end{itemize}
The recommended default is $\tau \in [1,5]$, e.g., $\tau=2$.
\item Convert pooled evidence $D(Q;T)$ into a probability-like weight with a sigmoid:
\[
w(Q) \;:=\; \sigma(D(Q;T)) \;=\; \frac{1}{1+\exp(-D(Q;T))}.
\]

Interpretation:
\begin{itemize}
    \item $w(Q)\approx 1$: strong supporting evidence exists and dominates.
    \item $w(Q)\approx 0$: strong contradictory evidence exists and dominates.
    \item $w(Q)\approx 0.5$: overall neutral / mixed / insufficient evidence.
\end{itemize}
\end{itemize}
This $w(Q)$ is used as the soft constraint weight in downstream reasoning (e.g., in a likelihood factor $\lambda(\varphi)$ that prefers readings satisfying $Q$).

\paragraph{Algorithm Summary:}
We complete the following steps
\\
\textbf{Step 1:} Preprocessing (once per document)

\begin{enumerate}
    \item Segment the document $T$ into segments $S(T)=\{s_i\}$.
    \item Compute SBERT embeddings $v_i = e(s_i)$ for all segments.
    \item Build an ANN index for fast top-$K$ similarity search (optional but recommended).
\end{enumerate}

\textbf{Step 2:} Per soft constraint $Q$

\begin{enumerate}
    \item Create hypothesis set $\mathcal{H}(Q)=\{h_1,\dots,h_r\}$ (optionally $r>1$ via paraphrases).
    \item For each $h_j$, retrieve top-$K$ segments $E_j$ by SBERT similarity.
    \item Form $E = \cup_j E_j$, deduplicate, and cap to $K_{\text{total}}$.
    \item For each $p\in E$, compute NLI logits against each $h_j$ and set
    \[
    d(p) = \max_{h_j} (z_{\text{ent}}(p,h_j) - z_{\text{con}}(p,h_j)).
    \]
    \item Aggregate with log-sum-exp pooling:
    \[
    D = \frac{1}{\tau}\log\left(\frac{1}{|E|}\sum_{p\in E} \exp(\tau d(p))\right).
    \]
    \item Output weight:
    \[
    w(Q)=\sigma(D).
    \]
\end{enumerate}

\textbf{Defaults:} We use the following settings.

\begin{itemize}
    \item Segments: short paragraphs (1–5 sentences).
    \item Paraphrases: $r=5$ (or $r=1$ if cost-sensitive).
    \item SBERT retrieval: $K=20$ per paraphrase.
    \item Deduplicated budget: $K_{\text{total}}=50$.
    \item NLI model: any 3-way entailment/contradiction/neutral cross-encoder (e.g., \texttt{cross-encoder/nli-deberta-v3-base} \cite{he2021deberta}).
    \item Temperature: $\tau = 2$.
\end{itemize}


\subsection{Comparing proposition versus FOL logic}


\begin{table}[h!]
\centering
\small
\begin{tabular}{lcc}
\toprule
\textbf{Dataset} & \textbf{Logic-LM Exec} & \textbf{Logify Exec} \\
\midrule
ProofWriter (prop-like) & 99.0 & 99.4 \\
FOLIO (FOL) & 85.8 & 91.2 \\
\bottomrule
\end{tabular}
\caption{Execution rates. Propositional-like tasks achieve near-perfect translation.}
\label{tab:propositional_vs_FOL}
\end{table}

\subsection{Usage Modes}
\label{sec:usage}

The system supports two primary modes:

\paragraph{Logify mode.}
Create a new logified structure from text:
\begin{verbatim}
python main.py from_text_to_logic --text "document.txt"
\end{verbatim}

\paragraph{Query mode.}
Ask questions, optionally adding new text:
\begin{verbatim}
python main.py query --query "Is X true?"
python main.py query --query "Is X true?" --text "additional_text.txt"
\end{verbatim}

In query mode with additional text, the system first updates the logified structure (Section~\ref{sec:from_text_to_logic}), then processes the query.


\subsection{OpenIE Extraction with Stanford CoreNLP}
\label{sec:openie}

The first stage of our extraction pipeline uses Stanford CoreNLP's Open Information Extraction (OpenIE) system \cite{angeli2015openie} to extract relation triples from natural language text. We access CoreNLP through the Stanza Python interface \cite{qi2020stanza}, which provides the official Python bindings maintained by the Stanford NLP Group.

\subsubsection{Pipeline Configuration}

Our OpenIE extraction pipeline is configured with the following annotators, applied in sequence:
\begin{enumerate}
    \item \texttt{tokenize}: Tokenization into words
    \item \texttt{ssplit}: Sentence splitting
    \item \texttt{pos}: Part-of-speech tagging
    \item \texttt{lemma}: Lemmatization
    \item \texttt{ner}: Named entity recognition
    \item \texttt{depparse}: Dependency parsing
    \item \texttt{coref}: Coreference resolution
    \item \texttt{natlog}: Natural logic annotations
    \item \texttt{openie}: Open information extraction
\end{enumerate}

\subsubsection{Coreference Resolution}

A key feature of our pipeline is the integration of coreference resolution \cite{lee2017coref} \emph{before} OpenIE extraction. This ensures that relation triples refer to canonical entity mentions rather than pronouns. For example, given the text:
\begin{quote}
``Dr.\ Martinez reviewed the patient's chart. She noted elevated blood pressure.''
\end{quote}
Without coreference resolution, OpenIE might extract:
\begin{center}
\texttt{(She; noted; elevated blood pressure)}
\end{center}
With coreference resolution enabled (\texttt{openie.resolve\_coref=true}), the triple becomes:
\begin{center}
\texttt{(Dr.\ Martinez; noted; elevated blood pressure)}
\end{center}
This resolution is critical for downstream logic conversion, as it ensures propositions are grounded to specific entities.

\subsubsection{Dependency Parse Fallback}

OpenIE may fail to extract triples from certain sentence structures, particularly:
\begin{itemize}
    \item Intransitive verbs with adverbial modifiers (e.g., ``Alice studies hard'')
    \item Sentences where the POS tagger misclassifies verbs as nouns
    \item Complex subordinate clause structures
\end{itemize}

To address this, we implement a dependency parse fallback mechanism. When OpenIE produces no triples for a sentence, we analyze the dependency parse to extract subject-verb-object or subject-verb-adverb relations. For example, from the dependency structure of ``Alice studies hard,'' we extract:
\begin{center}
\texttt{(Alice; studies; hard)}
\end{center}
These fallback triples are marked with lower confidence (0.7--0.8) compared to OpenIE triples (typically 0.9--1.0).

\subsubsection{Output Format}

The OpenIE stage outputs a list of relation triples in tab-separated format:
\begin{verbatim}
Subject    Predicate    Object    Confidence
Dr. Martinez    reviewed    patient's chart    0.95
Dr. Martinez    noted    elevated blood pressure    0.92
\end{verbatim}

These triples, along with the original text, are passed to Stage 2 (LLM-based logic conversion) as structured input.


\subsection{Logic Conversion Prompt}
\label{sec:prompt}

The second stage of our pipeline uses a large language model (GPT-4) to convert the original text and OpenIE triples into structured propositional logic. Below we provide the complete system prompt used for this conversion.

\subsubsection{Design Principles}

The prompt is designed with the following principles:
\begin{enumerate}
    \item \textbf{Faithfulness}: Prioritize accurate representation of the source text over completeness.
    \item \textbf{Atomicity}: Ensure primitive propositions cannot be further decomposed.
    \item \textbf{Independence}: Propositions should be logically independent (no redundancy).
    \item \textbf{Provenance}: Every extracted element must include textual evidence.
    \item \textbf{No weight extraction}: Soft constraints are identified but weights are assigned separately (Appendix~\ref{sec:weights}).
\end{enumerate}

\subsubsection{System Prompt}

The following is the system prompt provided to the LLM:

\begin{quote}
\small
\textbf{ROLE:} You are a neuro-symbolic reasoning assistant and expert logician that translates natural language text into structured zeroth-order propositional logic, with the assistance of preprocessed OpenIE relation triples.

\textbf{TASK:} Given a natural language text $T$ and its corresponding OpenIE relation triples, extract:

\begin{enumerate}
    \item \textbf{Atomic, primitive propositions} denoted $P_1, P_2, \ldots, P_n$. Each primitive propositional variable should be independent, contain no logical connectives, and be equipped with its natural language meaning along with short evidence from the text. Leverage the OpenIE triples to identify key relations and entities, but ensure propositions are atomic.

    \item \textbf{Hard constraints} which are zeroth-order propositional formulas over the variables $P_1, P_2, \ldots, P_n$ that must hold. These should include their meaning from the text, and evidence for why it is a required constraint. Use the OpenIE triples to identify explicit relationships and logical dependencies.

    \item \textbf{Soft constraints} which are also zeroth-order propositional formulas over the variables $P_1, P_2, \ldots, P_n$ that might hold. These are equipped with their meaning and evidence for why it is a soft constraint. Soft constraints reflect hedged or probabilistic language in the text (e.g., ``typically,'' ``sometimes,'' ``may'').
\end{enumerate}

\textbf{METHODOLOGY:}
\begin{itemize}
    \item \textbf{Step 1:} Analyze OpenIE triples to understand extracted entities and relationships.
    \item \textbf{Step 2:} Define primitive propositions---atomic, truth-evaluable statements.
    \item \textbf{Step 3:} Extract hard constraints---formulas that must hold per the text.
    \item \textbf{Step 4:} Extract soft constraints---formulas that may hold (defeasible statements).
\end{itemize}

\textbf{GUIDELINES:}
\begin{itemize}
    \item Use zeroth-order (propositional) logic only.
    \item Flatten first-order-like expressions: e.g., \texttt{Study(Alice, Tuesday)} becomes ``Alice studies on Tuesday.''
    \item Be faithful to the spirit of the text; do not add artificial primitives or constraints.
    \item When OpenIE triples conflict with the text, prioritize the original text.
\end{itemize}

\textbf{GRAMMAR:} Given a set $P$ of propositional variables, formulas are defined inductively:
\begin{enumerate}
    \item Every propositional variable is a formula.
    \item If $p$ is a formula, then $\neg p$ is a formula.
    \item If $p$ and $q$ are formulas, then $p \land q$, $p \lor q$, $p \Rightarrow q$, and $p \Leftrightarrow q$ are formulas.
\end{enumerate}
Use parentheses for grouping. Standard precedence and right-associativity apply.

\textbf{OUTPUT FORMAT:} Return valid JSON with the following structure:
\begin{verbatim}
{
  "primitive_props": [
    {"id": "P_1", "translation": "...",
     "evidence": "...", "explanation": "..."}
  ],
  "hard_constraints": [
    {"id": "H_1", "formula": "...",
     "translation": "...", "evidence": "...",
     "reasoning": "..."}
  ],
  "soft_constraints": [
    {"id": "S_1", "formula": "...",
     "translation": "...", "evidence": "...",
     "reasoning": "..."}
  ]
}
\end{verbatim}
\end{quote}

\subsubsection{Input Format}

The LLM receives input in the following format:
\begin{verbatim}
ORIGINAL TEXT:
<<<
[Natural language text T]
>>>

OPENIE TRIPLES:
<<<
[Tab-separated triples: subject  predicate  object  confidence]
>>>
\end{verbatim}

\subsubsection{Few-Shot Examples}

To improve extraction quality, the prompt includes few-shot examples demonstrating the expected input-output mapping. These examples illustrate:
\begin{itemize}
    \item How to identify atomic propositions from complex sentences
    \item The distinction between hard constraints (definite language) and soft constraints (hedged language)
    \item Proper use of logical connectives and formula structure
    \item How to provide evidence and reasoning for each extracted element
\end{itemize}

A complete example is provided in Appendix~\ref{sec:exemplar}.


\subsection{Extraction Exemplar}
\label{sec:exemplar}

This section provides a complete worked example demonstrating the logic conversion process. This example is included in the few-shot prompt to guide the LLM.

\subsubsection{Input Text}

\begin{quote}
The hospital's emergency triage protocol requires immediate attention for patients presenting with chest pain, unless the pain is clearly musculoskeletal in origin and the patient is under 40 years old. Dr.\ Martinez, who has been working double shifts this week, believes that patients over 65 should always receive an ECG regardless of symptoms, although Dr.\ Yang only sometimes believes this. The official guidelines only mandate this when cardiac history is documented.
\end{quote}

\subsubsection{Expected Output}

\paragraph{Primitive Propositions:}

\begin{itemize}
    \item[$P_1$:] ``The patient requires immediate attention under the hospital's emergency triage protocol.'' \\
    \textit{Evidence:} Sentence 1, ``The hospital's emergency triage protocol requires immediate attention for patients presenting with chest pain.'' \\
    \textit{Explanation:} Cannot be further broken down; it is an unambiguous, complete, and specific statement which is true/false evaluable.

    \item[$P_2$:] ``The patient presents with chest pain that is not clearly musculoskeletal in origin.'' \\
    \textit{Evidence:} Sentence 1, compound statement involving chest pain presentation. \\
    \textit{Explanation:} Note that ``not'' coming before ``clearly'' is important. This proposition is independent from $P_3$. The simpler ``The patient presents with chest pain'' is captured by $P_2 \lor P_3$.

    \item[$P_3$:] ``The patient presents with chest pain that is clearly musculoskeletal in origin.'' \\
    \textit{Evidence:} Sentence 1, ``unless the pain is clearly musculoskeletal in origin.'' \\
    \textit{Explanation:} A specific statement that is independent of the other $P_i$.

    \item[$P_4$:] ``The patient is under 40 years old.'' \\
    \textit{Evidence:} Sentence 1, ``the patient is under 40 years old.'' \\
    \textit{Explanation:} A specific statement that cannot be further broken down.

    \item[$P_5$:] ``Dr.\ Martinez works double shifts this week.'' \\
    \textit{Evidence:} Sentence 2, ``who has been working double shifts this week.''

    \item[$P_6$:] ``The patient is over 65 years old.'' \\
    \textit{Evidence:} Sentence 2, ``patients over 65.''

    \item[$P_7$:] ``Dr.\ Martinez makes sure the patient receives an ECG.'' \\
    \textit{Evidence:} Sentence 2, Dr.\ Martinez's belief about ECGs.

    \item[$P_8$:] ``Dr.\ Martinez follows the official guidelines.'' \\
    \textit{Evidence:} Sentence 3, ``The official guidelines only mandate this...'' \\
    \textit{Explanation:} Inferred from common sense that doctors follow guidelines. Needed for the constraint $H_4$.

    \item[$P_9$:] ``Dr.\ Yang follows the official guidelines.'' \\
    \textit{Evidence:} Similar to $P_8$.

    \item[$P_{10}$:] ``Dr.\ Yang makes sure the patient receives an ECG.'' \\
    \textit{Evidence:} Sentence 2, Dr.\ Yang's belief about ECGs.

    \item[$P_{11}$:] ``The patient has a documented cardiac history.'' \\
    \textit{Evidence:} Sentence 3, ``when cardiac history is documented.''
\end{itemize}

\paragraph{Hard Constraints:}

\begin{itemize}
    \item[$H_1$:] $(P_2 \land \neg(P_3 \land P_4)) \Rightarrow P_1$ \\
    \textit{Translation:} ``If the patient presents with chest pain and it is not true that both the pain is musculoskeletal in origin and the patient is under 40 years old, then the patient requires immediate attention.'' \\
    \textit{Evidence:} Sentence 1. \\
    \textit{Reasoning:} The word ``unless'' suggests an additional hypothesis, namely $\neg(P_3 \land P_4)$. We prefer not to rewrite this as $\neg P_3 \lor \neg P_4$ to remain faithful to the text structure.

    \item[$H_2$:] $P_5$ \\
    \textit{Translation:} ``Dr.\ Martinez works double shifts this week.'' \\
    \textit{Reasoning:} Stated as fact in the text.

    \item[$H_3$:] $P_6 \Rightarrow P_7$ \\
    \textit{Translation:} ``If the patient is over 65 years old, then Dr.\ Martinez makes sure the patient receives an ECG.'' \\
    \textit{Evidence:} Sentence 2, ``believes that patients over 65 should always receive an ECG.'' \\
    \textit{Reasoning:} Although stated as a belief, the text intends to describe Dr.\ Martinez's actions. The word ``always'' indicates this is a hard constraint.

    \item[$H_4$:] $((P_8 \land P_{11}) \Rightarrow P_7) \land ((P_9 \land P_{11}) \Rightarrow P_{10})$ \\
    \textit{Translation:} ``If Dr.\ Martinez follows the guidelines and the patient has documented cardiac history, then Dr.\ Martinez ensures an ECG. And similarly for Dr.\ Yang.'' \\
    \textit{Evidence:} Sentence 3, ``The official guidelines only mandate this when cardiac history is documented.'' \\
    \textit{Reasoning:} Because this constraint applies to all doctors, we flatten to propositional logic by instantiating for each doctor mentioned.
\end{itemize}

\paragraph{Soft Constraints:}

\begin{itemize}
    \item[$S_1$:] $P_6 \Rightarrow P_{10}$ \\
    \textit{Translation:} ``If the patient is over 65 years old, then Dr.\ Yang makes sure the patient receives an ECG.'' \\
    \textit{Evidence:} Sentence 2, ``although Dr.\ Yang only sometimes believes this.'' \\
    \textit{Reasoning:} Although stated as a belief, the text intends to describe Dr.\ Yang's actions. The word ``sometimes'' indicates this is a soft constraint, not a hard constraint.
\end{itemize}

\subsubsection{Key Observations}

This example illustrates several important aspects of the extraction process:

\begin{enumerate}
    \item \textbf{Linguistic cues for hard vs.\ soft}: The word ``always'' (Dr.\ Martinez) yields a hard constraint, while ``sometimes'' (Dr.\ Yang) yields a soft constraint for the same logical structure.

    \item \textbf{Flattening universal quantification}: The guideline ``applies to all doctors'' is flattened to propositional logic by creating separate propositions and constraints for each doctor mentioned in the text.

    \item \textbf{Preserving text structure}: The ``unless'' clause is represented as $\neg(P_3 \land P_4)$ rather than the logically equivalent $\neg P_3 \lor \neg P_4$, maintaining fidelity to the source text.

    \item \textbf{No weights in output}: Soft constraints are identified but do not include weight values. Weights are assigned separately by the evidence-based pipeline (Appendix~\ref{sec:weights}).
\end{enumerate}


\subsection{Worked Example: START and Jump-START Triage}
\label{sec:start_example}

We illustrate our constructions on the following text $T$:

\begin{quote}
\emph{``The START triage system is widely used in the United States;
it is utilized for patients above age $8$; it is intended that triage status can be computed in under $60$ seconds.
For children, a commonly used algorithm is Jump-START, which is based on START but accounts for pediatric respiratory failure risk
and difficulty following verbal commands. Triage is a dynamic process, and a patient can change triage status over time.''}
\end{quote}

\subsubsection{Extraction Pipeline}

We fix an LLM pipeline $\Pi$ and extract the following atomic propositions
$\mathcal{P}(T)=\{P_1,\dots,P_9\}$, where:
\begin{itemize}
\item $P_1$: ``The START system is (one of) the most common triage systems in the United States.''
\item $P_2$: ``START is utilized for patients above the age of $8$ years.''
\item $P_3$: ``Using START, triage status is intended to be calculated in less than $60$ seconds.''
\item $P_4$: ``For children, Jump-START is a commonly used triage algorithm.''
\item $P_5$: ``Jump-START is based on START.''
\item $P_6$: ``Jump-START accounts for increased pediatric risk of respiratory failure.''
\item $P_7$: ``Children may be unable to follow verbal commands.''
\item $P_8$: ``Triage is a dynamic process.''
\item $P_9$: ``A patient can change triage status over time.''
\end{itemize}

We obtain a set of hard constraints $\mathcal{C}(T)=\{C_1,C_2,C_3,C_4\}$, intended to capture structural claims of the text:
\begin{enumerate}
\item[$C_1$:] $P_8 \rightarrow P_9$ — ``dynamic'' implies change over time is possible.
\item[$C_2$:] $P_4 \rightarrow P_5$ — Jump-START for children $\Rightarrow$ based on START.
\item[$C_3$:] $P_4 \rightarrow P_6$ — Jump-START for children $\Rightarrow$ accounts for respiratory failure risk.
\item[$C_4$:] $P_4 \rightarrow P_7$ — Jump-START for children $\Rightarrow$ inability to follow commands relevant.
\end{enumerate}

We also specify soft constraints $\mathcal{S}(T) = \{S_1, S_2, S_3\}$ with confidence weights:
\begin{itemize}
\item $S_1 := P_1$ with $w(S_1) = 0.75$ (``widely used'' suggests high but not certain confidence)
\item $S_2 := P_2$ with $w(S_2) = 0.60$ (age threshold stated but not absolute)
\item $S_3 := P_3$ with $w(S_3) = 0.85$ (``intended'' is strong but not guaranteed)
\end{itemize}

\subsubsection{Knowledge Algebra Construction}

Let $\mathcal{R}(T)$ denote the Boolean ring associated to $(T,\Pi)$, obtained by enforcing the hard constraints in $\mathcal{C}(T)$:
\begin{align*}
\mathcal{R}(T) =
\frac{
\mathbb{F}_2[P_i \mid 1 \leq i \leq 9]
}
{
\langle
P_i^2 + P_i \mid 1 \leq i \leq 9
\rangle
+
\mathcal{I}_{\mathcal{C}}(T)
}
\end{align*}
where
\[
\mathcal{I}_{\mathcal{C}}(T)
=
\langle
P_8(1+P_9),\;
P_4(1+P_5),\;
P_4(1+P_6),\;
P_4(1+P_7)
\rangle.
\]

A \emph{reading} is a morphism $\varphi:\mathcal{R}(T)\to\mathbb{F}_2$.
We weight readings using the soft constraint polynomials. For each soft constraint $C$ with weight $w(C)$, define:
\[
\lambda_C(\varphi)=
\begin{cases}
w(C) & \text{if } \varphi(C) = 1,\\
1-w(C) & \text{if } \varphi(C) = 0,
\end{cases}
\]
which induces the unnormalized weight:
\[
W(\varphi)=\prod_{C\in\mathcal{S}(T)} \lambda_C(\varphi).
\]

\subsubsection{Comparing Two Readings}

We exhibit two admissible readings (both satisfy all hard constraints) with different weights.

\paragraph{Reading A.} Assume $\varphi_A$ satisfies $P_1, P_2, P_3, P_4, P_8$. The hard constraints also imply $P_5, P_6, P_7, P_9$.
Since $\varphi_A$ satisfies all soft constraints ($P_1=1, P_2=1, P_3=1$), its weight is:
\[
W(\varphi_A) = (0.75)(0.60)(0.85) = 0.3825.
\]

\paragraph{Reading B.} Assume $\varphi_B$ satisfies $P_4, P_8$ (and consequently $P_5, P_6, P_7, P_9$), but $\varphi_B$ does \emph{not} satisfy $P_1$ and $P_3$ (treating them as false), while still satisfying $P_2$.
The contributions are:
\begin{itemize}
    \item $P_1$: Violated $\to (1-0.75) = 0.25$
    \item $P_2$: Satisfied $\to 0.60$
    \item $P_3$: Violated $\to (1-0.85) = 0.15$
\end{itemize}
Then:
\[
W(\varphi_B) = (0.25)(0.60)(0.15) = 0.0225.
\]

Thus, both readings are admissible under the hard constraints, but Reading A is significantly preferred by the soft-constraint weighting ($W(\varphi_A) / W(\varphi_B) = 17$).


\subsection{Algebraic Reasoning: Consequence and Compatibility}
\label{sec:algebraic_reasoning}

In this section, we describe algebraic tests for consequence, inconsistency, and compatibility. Throughout, we work relative to a fixed text $T$ and pipeline $\Pi$, writing $\mathcal{R}(T)$ for the knowledge algebra and $\mathcal{I}_{\mathcal{C}}(T)$ for the hard-constraint ideal.

\subsubsection{Testing Consequence and Inconsistency}

Let $Q$ be a query proposition and let $q := \Pi_{\mathrm{form}}(Q) \in \mathcal{R}(T)$ denote its grounded Boolean formula.

\begin{proposition}
\label{prop:consequence_inconsistency}
Let $q := \Pi_{\mathrm{form}}(Q) \in \mathcal{R}(T)$ encode a query proposition $Q$.
\begin{enumerate}
\item $Q$ is a \emph{$\Pi$-consequence} of $T$ (i.e., $Q$ is True under every reading) if and only if
\[
1+q \in \mathcal{I}_{\mathcal{C}}(T).
\]
\item $Q$ is \emph{$\Pi$-inconsistent} with $T$ (i.e., $Q$ is False under every reading) if and only if
\[
q \in \mathcal{I}_{\mathcal{C}}(T).
\]
\end{enumerate}
\end{proposition}

\paragraph{Example.}
Let $Q_1$ denote the proposition \emph{``If triage is dynamic then a patient can change triage status over time,''} i.e., $Q_1 := P_8 \rightarrow P_9$.
In our Boolean ring encoding:
\[
q_1 = \Pi_{\mathrm{form}}(Q_1) = 1 + P_8(1+P_9).
\]
Since $C_1$ is a hard constraint, the polynomial $P_8(1+P_9)$ lies in $\mathcal{I}_{\mathcal{C}}(T)$, hence $1+q_1 = P_8(1+P_9) \in \mathcal{I}_{\mathcal{C}}(T)$.
By Proposition~\ref{prop:consequence_inconsistency}, $Q_1$ is a $\Pi$-consequence of $T$.

\subsubsection{Testing Relative Compatibility}

Given two propositions $S$ and $R$, we may test whether they can be simultaneously True under the hard constraints.

\begin{proposition}
\label{prop:compatibility}
Let $s := \Pi_{\mathrm{form}}(S)$ and $r := \Pi_{\mathrm{form}}(R)$ be the Boolean-ring encodings of two propositions.
Then $S$ and $R$ are \emph{mutually $\Pi$-incompatible} with respect to $T$ (i.e., there is no reading under which both are True) if and only if
\[
sr \in \mathcal{I}_{\mathcal{C}}(T).
\]
\end{proposition}

\paragraph{Example.}
Let $S := P_8$ (``triage is dynamic'') and $R := \neg P_9$ (``a patient cannot change status over time'').
Then:
\[
sr = P_8(1+P_9).
\]
Because $P_8 \rightarrow P_9$ is a hard constraint, the polynomial $P_8(1+P_9)$ lies in $\mathcal{I}_{\mathcal{C}}(T)$, hence $sr \in \mathcal{I}_{\mathcal{C}}(T)$.
By Proposition~\ref{prop:compatibility}, the propositions $P_8$ and $\neg P_9$ cannot be simultaneously True in any admissible reading.

\subsubsection{Underdetermination}

A \emph{reading} is a morphism $\varphi: \mathcal{R}(T) \to \mathbb{F}_2$, corresponding to a satisfying assignment to the hard constraints. The number of readings quantifies how much the text leaves undetermined.

\begin{definition}[Underdetermination]
\label{def:underdetermination}
Given a text $T$ and a pipeline $\Pi$, let $N(T)$ be the number of readings:
\[
N(T) := \bigl|\mathrm{Hom}(\mathcal{R}(T), \mathbb{F}_2)\bigr|.
\]
We define the \emph{underdetermination ratio} by:
\[
\mathrm{Und}(T,\Pi) := \frac{\log_2 N(T)}{n},
\qquad 0 \leq \mathrm{Und}(T,\Pi) \leq 1,
\]
where $n$ is the number of extracted atoms.
\end{definition}

\paragraph{Example.}
Consider a reduced proposition set $\mathcal{P}(T) = \{P_3, P_4, P_5, P_8, P_9\}$ ($n=5$), with hard constraints $P_8 \rightarrow P_9$ and $P_4 \rightarrow P_5$.
Each implication forbids exactly one assignment on its pair of variables (True $\land$ False), hence each contributes $3$ satisfying assignments out of $4$.
The number of readings is:
\[
N(T) = 3 \cdot 3 \cdot 2 = 18,
\]
where the final factor $2$ comes from the unconstrained variable $P_3$.
Thus:
\[
\mathrm{Und}(T,\Pi) = \frac{\log_2(18)}{5} \approx 0.834.
\]
This value reflects that the hard constraints eliminate some combinations but still leave substantial freedom.

\paragraph{Remark.}
Soft constraints $\mathcal{S}(T)$ with confidences $w(C) \in (0,1)$ do not change the admissible readings determined by $\mathcal{I}_{\mathcal{C}}(T)$; instead they define a weight $W(\varphi)$ that ranks readings by plausibility. This supports \emph{weighted} variants of underdetermination (e.g., effective model count or entropy) without turning defeasible statements into hard logical necessities

\subsection{Baseline Choices}

We establish a comprehensive set of baselines to evaluate our framework across different document lengths and reasoning paradigms.

\paragraph{Short-form reasoning tasks (FOLIO, ProofWriter).}
For datasets with concise premises that fit within context windows, we compare against:
\begin{itemize}
    \item \textbf{Logic-LM} \cite{pan2023logiclm}: The most directly comparable neuro-symbolic system. Logic-LM translates problems into symbolic formulations per query, allowing us to isolate the value of our ``logify once, query many'' paradigm.
    \item \textbf{Reasoning LLM}: A modern reasoning-capable model (e.g., o1-mini) with chain-of-thought. This tests whether improved native reasoning eliminates the need for symbolic delegation.
\end{itemize}

\paragraph{Long-form document reasoning (ContractNLI).}
For documents exceeding typical context limits, direct application of Logic-LM is infeasible. We therefore evaluate:
\begin{itemize}
    \item \textbf{Logic-LM + RAG}: Logic-LM applied to retrieved passages only. This hybrid baseline tests whether per-query formalization over retrieved context can match our full-document logification.
    \item \textbf{Reasoning LLM + RAG}: State-of-the-art reasoning models with retrieval augmentation. This establishes whether symbolic reasoning provides value beyond advanced retrieval and native reasoning chains.
\end{itemize}

\paragraph{Objectives.}
This baseline design allows us to answer three critical questions: (1) Does logifying once outperform per-query formalization when both are feasible? (2) Does full-document logification overcome retrieval gaps in long documents? (3) Is symbolic reasoning necessary given modern reasoning-capable LLMs?


\subsection{Logic Solver Implementation Details}
\label{sec:logic_solver_impl}

This section describes the implementation of the \texttt{logic\_solver} module, which performs weighted MaxSAT reasoning over the logified structure. Our implementation uses PySAT's RC2 solver \cite{ignatiev2019rc2}, a state-of-the-art core-guided MaxSAT algorithm that ranked first in both weighted and unweighted complete categories of the MaxSAT Evaluations 2018 and 2019.

\subsubsection{Weighted CNF Encoding}

The \texttt{logic\_solver} module encodes the logified structure as a Weighted Conjunctive Normal Form (WCNF) formula compatible with MaxSAT solvers. The encoding process consists of three stages:

\paragraph{Proposition Mapping.}
Each extracted proposition $P_i \in \mathcal{P}(T)$ is mapped to a unique Boolean variable $x_i \in \{1, 2, \ldots, n\}$ for SAT solving. This mapping is maintained bidirectionally to support result interpretation.

\paragraph{Hard Constraint Encoding.}
Each hard constraint $C \in \mathcal{C}(T)$ is converted to CNF clauses using a recursive descent parser with the following transformations:
\begin{itemize}
    \item Formulas are parsed into abstract syntax trees respecting operator precedence: $\neg$ (NOT), $\land$ (AND), $\lor$ (OR), $\Rightarrow$ (IMPLIES), $\Leftrightarrow$ (IFF)
    \item Negation Normal Form (NNF) is computed by pushing negations to literals using De Morgan's laws
    \item CNF conversion applies the distributive law to NNF expressions
\end{itemize}
Hard constraint clauses are added to the WCNF with infinite weight, making them mandatory.

\paragraph{Soft Constraint Encoding.}
Each soft constraint $C_k \in \mathcal{S}(T)$ with confidence weight $w_k \in (0,1)$ is converted to CNF clauses and added to the WCNF with finite weight. Following the log-odds transformation described in Section~\ref{sec:maxsat}, we compute:
\[
\text{weight}(C_k) = \frac{w_k}{1 - w_k} \times 1000
\]
and round to the nearest integer. The scaling factor of 1000 provides sufficient precision for typical weight distributions while maintaining computational efficiency.

\subsubsection{RC2 MaxSAT Solver}

We use PySAT's implementation of the RC2 (Relaxable Cardinality Constraints) algorithm \cite{ignatiev2019rc2}, which is based on the OLLITI core-guided approach. RC2 has several advantages over earlier branch-and-bound solvers like MiniMaxSAT \cite{heras2007minimaxsat}:

\begin{itemize}
    \item \textbf{Core-guided search}: Instead of exhaustively exploring a branch-and-bound tree, RC2 iteratively extracts unsatisfiable cores and relaxes them via cardinality constraints. This approach scales better to large instances with many soft constraints.

    \item \textbf{Incremental solving}: RC2 reuses learned information across iterations, making it efficient for repeated queries over the same knowledge base.

    \item \textbf{Heuristic optimizations}: RC2 implements unsatisfiable core exhaustion, core reduction, and intrinsic AtMost1 constraint detection, which significantly improve performance on structured problems.
\end{itemize}

The solver interface supports any SAT backend provided by PySAT; we use Glucose 3 \cite{audemard2009glucose} as the default backend due to its strong performance on industrial instances.

\subsubsection{Query Processing}

Given a natural language query $Q$ translated to a formal constraint $q$, the solver performs the following reasoning tasks:

\paragraph{Entailment Check.}
To test whether $\mathcal{R}(T) \models q$, we:
\begin{enumerate}
    \item Create a copy of the base WCNF formula
    \item Encode $\neg q$ as hard clauses and add them to the formula
    \item Invoke the SAT solver to check satisfiability
    \item If UNSAT, then $q$ is entailed (return TRUE with confidence 1.0)
    \item If SAT, proceed to consistency check
\end{enumerate}

\paragraph{Consistency Check.}
To test whether $\mathcal{R}(T) \land q$ is satisfiable, we:
\begin{enumerate}
    \item Create a copy of the base WCNF formula
    \item Encode $q$ as hard clauses and add them to the formula
    \item Invoke the SAT solver to check satisfiability
    \item If UNSAT, then $q$ contradicts the knowledge base (return FALSE with confidence 1.0)
    \item If SAT, proceed to confidence computation
\end{enumerate}

\paragraph{Confidence Computation.}
For queries that are neither entailed nor contradicted (UNCERTAIN), we compute confidence by comparing MaxSAT costs:
\begin{enumerate}
    \item Solve MaxSAT for $\mathcal{R}(T) \land q$ to obtain cost $c_q$
    \item Solve MaxSAT for $\mathcal{R}(T) \land \neg q$ to obtain cost $c_{\neg q}$
    \item Compute normalized confidence: $\text{conf}(q) = \frac{c_{\neg q}}{c_q + c_{\neg q}}$
\end{enumerate}
This measures the relative weight of violated soft constraints: if $\neg q$ violates more soft constraints than $q$, then $q$ receives higher confidence.

\subsubsection{Implementation Architecture}

The \texttt{logic\_solver} module consists of three main components:

\begin{itemize}
    \item \textbf{FormulaParser} (\texttt{encoding.py}): Recursive descent parser for propositional logic formulas with CNF conversion
    \item \textbf{LogicEncoder} (\texttt{encoding.py}): Converts logified JSON structures to WCNF format
    \item \textbf{LogicSolver} (\texttt{maxsat.py}): High-level interface for entailment, consistency, and confidence queries
\end{itemize}

The module is designed to be independent of the logification pipeline, accepting any JSON structure that conforms to the schema described in Section~\ref{sec:from_text_to_logic}. This modularity allows the symbolic reasoning component to be reused across different extraction methods or domain-specific customizations.

\subsubsection{Performance Characteristics}

For typical logified structures with $n \in [10, 100]$ propositions and $m \in [20, 200]$ constraints, query latency is dominated by SAT solving time:
\begin{itemize}
    \item \textbf{Entailment queries}: 5--50ms (single UNSAT check)
    \item \textbf{Consistency queries}: 5--50ms (single SAT check)
    \item \textbf{Confidence queries}: 20--200ms (two MaxSAT optimizations)
\end{itemize}

These timings are measured on standard benchmark hardware (Intel i7, 16GB RAM) and reflect the efficiency of modern SAT/MaxSAT solvers for propositional reasoning. For larger structures ($n > 500$), we recommend preprocessing to eliminate redundant constraints or splitting the knowledge base into independent components.

\subsubsection{Correctness Guarantees}

The correctness of the \texttt{logic\_solver} module depends on two factors:
\begin{enumerate}
    \item \textbf{Encoding correctness}: The CNF transformation must preserve satisfiability. Our implementation uses standard Tseitin-style transformations with careful handling of operator precedence and associativity.

    \item \textbf{Solver correctness}: RC2 is a complete and sound MaxSAT solver with formal correctness guarantees \cite{ignatiev2019rc2}. All entailment and consistency results are provably correct given the logified structure.
\end{enumerate}

\paragraph{Conditional Correctness.}
The system provides \emph{conditional correctness}: if the logified structure $(\mathcal{P}(T), \mathcal{C}(T), \mathcal{S}(T))$ faithfully represents the text $T$, then all solver outputs are logically sound. Errors in the logification pipeline (e.g., missing constraints, incorrect weights) propagate to downstream reasoning, but the solver itself introduces no additional errors.

This separation of concerns---extraction vs.\ reasoning---enables systematic debugging and quality control: extraction errors can be corrected by improving the LLM prompt or adding self-refinement loops, while reasoning correctness is guaranteed by the symbolic solver.

\subsection{Logic-LM++ Baseline Configuration}

We evaluate the Logic-LM++ baseline on the LogicBench-v1.0 propositional logic subset, specifically targeting \emph{modus tollens} reasoning tasks. The experiment uses GPT-4 as the underlying language model with temperature $T=0$ for deterministic outputs.

\paragraph{Formalization Strategy.}
A key design choice is the use of \textbf{propositional logic formalization} rather than first-order logic (FOL). The original Logic-LM framework employs FOL with quantifiers (e.g., $\forall x\, P(x) \rightarrow Q(x)$), which introduces parsing complexity when interfacing with the Z3 SMT solver. For propositional reasoning tasks, we instead prompt the LLM to produce ground propositional formulas using atomic variables (e.g., $P, Q, R$) connected by standard connectives ($\land, \lor, \rightarrow, \neg, \leftrightarrow$). This approach aligns with the Logify framework's design philosophy of using propositional logic for improved solver compatibility and eliminates quantifier instantiation errors.

\paragraph{Refinement Configuration.}
The refinement loop is configured with a minimum of 1 iteration (\texttt{min\_refinements=1}) and a maximum of 4 iterations (\texttt{max\_iterations=4}). At each iteration, the system generates $N=2$ candidate refinements, selects the best via pairwise LLM comparison, and applies the \textbf{backtracking agent}---the key Logic-LM++ innovation---to compare the selected refinement against the previous formulation. If no semantic improvement is detected, the system reverts to the previous version, preventing degradation. Early stopping occurs after 2 consecutive backtracks (\texttt{max\_consecutive\_backtracks=2}).

\paragraph{Solver Configuration.}
We use Z3 as the theorem prover with a 30-second timeout. The solver interface parses propositional formulas by: (1) extracting boolean variables from CamelCase identifiers, (2) replacing logical symbols ($\rightarrow, \land, \lor, \neg, \leftrightarrow$) with Z3 operators, and (3) constructing a satisfiability query to determine if the premises entail the conclusion.

\paragraph{Results Summary.}
On 20 modus tollens examples, the baseline achieves 50\% accuracy (10/20 correct) with 100\% execution rate ($E_r = 1.0$). Notably, all 20 examples triggered the backtracking agent with a \texttt{REVERT} decision, indicating that the generated refinements did not improve semantic fidelity over the initial formalization. The average query time is 10.9 seconds with 2 LLM calls per example (formalization + refinement attempt). The primary failure mode is incorrect predicate alignment---for instance, introducing a redundant variable $R$ (``decided against ordering pizza'') instead of recognizing it as $\neg Q$ (``did not order pizza'')---which breaks the logical chain required for modus tollens inference.

% Table: Logic-LM++ Baseline Summary Metrics
\begin{table}[h]
\centering
\caption{Logic-LM++ Baseline Results on LogicBench-v1.0 Modus Tollens}
\label{tab:logiclm-summary}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Dataset & LogicBench-v1.0 \\
Logic Type & Propositional \\
Task Type & BQA (Boolean QA) \\
Model & GPT-4 \\
Total Examples & 20 \\
\midrule
Overall Accuracy & 50.0\% (10/20) \\
Execution Rate ($E_r$) & 100.0\% (20/20) \\
Execution Accuracy ($E_a$) & 50.0\% \\
\midrule
Avg. Time per Query & 10.94 s \\
Avg. LLM Calls per Query & 2.0 \\
Backtracking Rate & 100\% REVERT \\
\bottomrule
\end{tabular}
\end{table}

% Table: Time Breakdown Analysis
\begin{table}[h]
\centering
\caption{Logic-LM++ Time Breakdown by Pipeline Stage}
\label{tab:logiclm-time}
\begin{tabular}{lcccc}
\toprule
\textbf{Stage} & \textbf{Mean (s)} & \textbf{Min (s)} & \textbf{Max (s)} & \textbf{\% of Total} \\
\midrule
Formalization & 2.21 & 1.62 & 3.44 & 20.2\% \\
Refinement & 8.73 & 3.29 & 15.37 & 79.8\% \\
Solving & 0.002 & 0.001 & 0.005 & 0.02\% \\
\midrule
\textbf{Total} & \textbf{10.94} & \textbf{4.91} & \textbf{18.81} & \textbf{100\%} \\
\bottomrule
\end{tabular}
\end{table}

% Table: Accuracy by Question Polarity
\begin{table}[h]
\centering
\caption{Logic-LM++ Accuracy by Question Polarity}
\label{tab:logiclm-polarity}
\begin{tabular}{lccc}
\toprule
\textbf{Question Type} & \textbf{Count} & \textbf{Correct} & \textbf{Accuracy} \\
\midrule
Positive query (``Does this entail $P$?'') & 10 & 2 & 20.0\% \\
Negative query (``Does this entail $\neg P$?'') & 10 & 8 & 80.0\% \\
\midrule
\textbf{Total} & \textbf{20} & \textbf{10} & \textbf{50.0\%} \\
\bottomrule
\end{tabular}
\end{table}

% Table: Formalization Quality Analysis
\begin{table}[h]
\centering
\caption{Formalization Patterns in Logic-LM++ Results}
\label{tab:logiclm-formalization}
\begin{tabular}{lcc}
\toprule
\textbf{Formalization Pattern} & \textbf{Count} & \textbf{Accuracy} \\
\midrule
Correct modus tollens: $P \to Q, \neg Q \vdash \neg P$ & 12 & 83.3\% (10/12) \\
Predicate misalignment: introduces $R \neq \neg Q$ & 6 & 16.7\% (1/6) \\
Variant: $P \to \neg Q, Q \vdash \neg P$ & 2 & 100\% (2/2) \\
\midrule
\textbf{Total} & \textbf{20} & \textbf{50.0\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{remark}[Interpretation of Logic-LM++ Results]
\label{rem:logiclm-interpretation}
The tables above reveal several important insights about the Logic-LM++ baseline:

\textbf{(1) Formalization is the bottleneck, not solving.} Table~\ref{tab:logiclm-time} shows that solving takes only 0.002 seconds on average ($<0.1\%$ of total time), while formalization and refinement dominate. This confirms that the symbolic reasoning component is efficient once the logical structure is correctly extracted---the challenge lies in accurate NL-to-logic translation.

\textbf{(2) Question polarity strongly affects accuracy.} Table~\ref{tab:logiclm-polarity} reveals a striking asymmetry: negative queries (``Does this entail $\neg P$?'') achieve 80\% accuracy, while positive queries (``Does this entail $P$?'') achieve only 20\%. This occurs because modus tollens naturally concludes $\neg P$ from premises $P \to Q$ and $\neg Q$. When the system correctly formalizes the problem, it proves $\neg P$---answering negative queries correctly but incorrectly answering ``yes'' to positive queries (since the solver proves $\neg P$, not $P$).

\textbf{(3) Predicate misalignment is the primary failure mode.} Table~\ref{tab:logiclm-formalization} shows that when the LLM correctly identifies the modus tollens structure ($P \to Q, \neg Q$), accuracy reaches 83.3\%. However, in 30\% of cases (6/20), the LLM introduces a redundant predicate $R$ (e.g., ``decided against pizza'') instead of recognizing it as $\neg Q$ (``did not order pizza''). This breaks the logical chain: with premises $\{P \to Q, R\}$, the conclusion $\neg P$ cannot be derived.

\textbf{(4) The backtracking agent correctly prevents degradation.} All 20 examples triggered REVERT decisions, indicating that refinement candidates did not improve upon the initial formalization. This validates the backtracking agent's design: it successfully prevents accepting syntactically correct but semantically inferior refinements.

\textbf{(5) Implications for Logify comparison.} The 50\% accuracy ceiling on modus tollens---a fundamental reasoning pattern---highlights the limitations of per-query formalization approaches. Logify's ``logify once, query many'' paradigm addresses this by constructing a reusable logical structure upfront, amortizing formalization errors across multiple queries and enabling self-refinement with richer context.
\end{remark}
