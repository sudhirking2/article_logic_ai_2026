================================================================================
NEGATION HANDLING FIX - VISUAL ARCHITECTURE
================================================================================

BEFORE FIX (Current System):
═══════════════════════════

┌─────────────────────────────────────────────────────────────────────┐
│ Hypothesis: "Receiving Party shall NOT disclose information"       │
│ (NEGATIVE - expresses prohibition)                                  │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Query Translation (translate.py)                                    │
│ • SBERT retrieves similar propositions                              │
│ • LLM translates to formula                                         │
│ • ❌ NO negation detection                                          │
│ • ❌ NO polarity validation                                         │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Retrieved: P_9 = "Receiving Party discloses information"           │
│ Formula: "P_9"  ← ❌ MISMATCH: negative hypothesis → positive formula│
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Solver (maxsat.py)                                                  │
│ • Entailment check: KB ⊨ P_9?                                       │
│   (Does KB say disclosure IS required?)                             │
│ • ❌ NO contradiction check                                         │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Result: UNCERTAIN                                                   │
│ ❌ WRONG: Should be TRUE (prohibition exists) or FALSE (contradicted)│
└─────────────────────────────────────────────────────────────────────┘


AFTER FIX (Proposed System):
═════════════════════════════

┌─────────────────────────────────────────────────────────────────────┐
│ Hypothesis: "Receiving Party shall NOT disclose information"       │
│ (NEGATIVE - expresses prohibition)                                  │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Query Translation (translate.py) + NEGATION FIX                     │
│ • SBERT retrieves similar propositions                              │
│ • ✅ Detect hypothesis is NEGATIVE                                  │
│ • LLM translates to formula                                         │
│ • ✅ Check polarity match                                           │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Retrieved: P_9 = "Receiving Party discloses information"           │
│            (AFFIRMATIVE proposition)                                │
│                                                                     │
│ LLM Formula: "P_9"  ← ⚠️ POLARITY MISMATCH DETECTED                │
│                                                                     │
│ Polarity Check:                                                     │
│   • Hypothesis: NEGATIVE ("shall not")                             │
│   • Formula: no negation operator                                  │
│   • Proposition: AFFIRMATIVE ("discloses")                         │
│   • ❌ INVALID: Polarities don't match                             │
│                                                                     │
│ Suggested Correction: "¬P_9"                                        │
│                                                                     │
│ [Conservative Mode]: Keep "P_9", log warning                        │
│ [Aggressive Mode]:  Auto-correct to "¬P_9" ✅                       │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Final Formula: "¬P_9"                                               │
│ (Checks if disclosure is PROHIBITED)                                │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Solver (maxsat.py) + CONTRADICTION FIX                              │
│                                                                     │
│ Step 1: Entailment Check                                            │
│   KB ⊨ ¬P_9?  (Is prohibition entailed?)                            │
│   → Check if KB ∧ ¬(¬P_9) = KB ∧ P_9 is UNSAT                       │
│                                                                     │
│ Step 2: Contradiction Check ✅ NEW!                                 │
│   If not entailed, check if KB ⊨ ¬(¬P_9) = KB ⊨ P_9                │
│   (Is the opposite—disclosure required—entailed?)                   │
│   → Check if KB ∧ ¬P_9 is UNSAT                                     │
│                                                                     │
│ Step 3: Three-Valued Result                                         │
│   • If KB ⊨ ¬P_9:     return TRUE     (prohibition exists)          │
│   • If KB ⊨ P_9:      return FALSE    (contradicted - disclosure    │
│                                         is required!)                │
│   • Otherwise:        return UNCERTAIN (not mentioned)              │
└──────────────────────────────┬──────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────────────────────────────────────────────────────┐
│ Result: TRUE or FALSE or UNCERTAIN                                  │
│ ✅ CORRECT: Now distinguishes absence from contradiction            │
└─────────────────────────────────────────────────────────────────────┘


CONCRETE EXAMPLE: ContractNLI Doc 3, Hypothesis nda-2
═══════════════════════════════════════════════════════

Input:
  Hypothesis: "Confidential Information shall only include technical information"
  Ground Truth: FALSE (contract includes non-technical info too)

Knowledge Base (KB):
  P_1 = "Confidential Information includes technical and non-technical information"
  H_1: P_1 (hard constraint - this is true)

BEFORE FIX:
───────────
  Query Translation:
    Retrieves: P_1
    Formula: "P_1"

  Solver:
    Check: KB ⊨ P_1?
    KB ∧ ¬P_1 = {P_1, ¬P_1} = UNSAT
    Result: TRUE (entailed)

  ❌ WRONG: Says "only technical" is TRUE, but ground truth is FALSE

AFTER FIX:
──────────
  Query Translation + Negation Detection:
    Hypothesis detected as RESTRICTIVE ("only include")
    Retrieves: P_1 = "includes technical and non-technical"
    LLM Formula: "P_1"

    Polarity Check:
      - Hypothesis: "only include technical" (restrictive → negative)
      - P_1: "includes technical AND non-technical" (affirmative)
      - MISMATCH: Hypothesis restricts to technical only, but P_1 includes both

    Suggested Correction: Hypothesis should check for absence of non-technical
    Better Formula: "¬(P_1)" or create P_2 = "includes only technical"

  Solver + Contradiction Check:
    Check: KB ⊨ ¬P_1? (Does KB say NOT "tech and non-tech"?)
    KB ∧ P_1 = {P_1, P_1} = SAT
    Result: Not entailed

    Check Contradiction: KB ⊨ P_1? (Does KB say "tech and non-tech"?)
    KB ∧ ¬P_1 = {P_1, ¬P_1} = UNSAT
    Result: P_1 is entailed (the opposite of hypothesis)

    Since hypothesis is "only technical" but KB entails "technical AND non-technical",
    this is a CONTRADICTION.

  ✅ Result: FALSE (contradicted)
  ✅ CORRECT: Matches ground truth


KEY INSIGHTS:
═════════════

1. POLARITY MATCHING:
   Hypothesis polarity ⟷ Formula polarity ⟷ Proposition polarity

   ┌────────────┬────────────┬────────────┬──────────┐
   │ Hypothesis │ Proposition│  Formula   │  Valid?  │
   ├────────────┼────────────┼────────────┼──────────┤
   │ "shall not"│ "does X"   │   P_i      │    ❌    │
   │ "shall not"│ "does X"   │  ¬P_i      │    ✅    │
   │ "shall not"│ "not do X" │   P_i      │    ✅    │
   │ "shall"    │ "does X"   │   P_i      │    ✅    │
   └────────────┴────────────┴────────────┴──────────┘

2. THREE-VALUED LOGIC:

   KB ⊨ Q?     KB ⊨ ¬Q?     Result
   ───────     ────────     ──────
     ✅          ❌         TRUE    (entailed)
     ❌          ✅         FALSE   (contradicted) ← NEW!
     ❌          ❌         UNCERTAIN (not mentioned)
     ✅          ✅         ERROR   (inconsistent KB)

3. ERROR PATTERN 1 FIX:

   Before: FALSE predictions = 0/7 (100% error rate)

   Issue 1: Polarity mismatches prevent correct formula construction
   Issue 2: No contradiction detection (only entailment check)

   After:  FALSE predictions = 5-6/7 (70-80% recall)

   Fix 1: Detect negation, validate polarity, auto-correct if needed
   Fix 2: Add contradiction check (KB ⊨ ¬Q?)


IMPLEMENTATION CHECKLIST:
═════════════════════════

□ Copy negation_fix_implementation.py to code/logic_solver/negation_fixes.py
□ Add import to translate.py
□ Modify translate_hypothesis() to call augment_translation_result()
□ Add import to maxsat.py
□ Add check_contradiction() method to MaxSATSolver class
□ Modify query() method to call check_contradiction()
□ Update evaluation scripts to enable flags
□ Run unit tests (expect 17/17 passing)
□ Run integration test on ContractNLI FALSE cases
□ Measure improvement: FALSE recall 0% → 70-80%
□ Update paper with new results

================================================================================
