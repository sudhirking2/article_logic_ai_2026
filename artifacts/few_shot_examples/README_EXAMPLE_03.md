# Example 03: Student Assessment Rules - COMPLETED

## Overview

This is the third exemplar added to `prompt_logify2`, demonstrating logification of student assessment rules with exclusive-OR logic and biconditionals.

**Status:** ✅ COMPLETED using actual LOGIFY2.py code with OpenAI API

---

## Input Text

```
Students must complete either the written exam or the oral presentation, but not both, to satisfy the assessment requirement. A student passes the course if and only if they satisfy the assessment requirement and attend at least 80% of lectures. Students may request deadline extensions, though approval requires documented extenuating circumstances.
```

---

## Key Logical Features

1. **Exclusive-OR (XOR)**: "either...but not both"
   - Formula: `P_3 ⟺ ((P_1 ∨ P_2) ∧ ¬(P_1 ∧ P_2))`

2. **Biconditional (IFF)**: "if and only if"
   - Formula: `P_5 ⟺ (P_3 ∧ P_4)`

3. **Necessary Condition**: "requires"
   - Formula: `P_7 ⟹ (P_8 ∧ P_9)`

4. **Modal Permission**: "may"
   - Hard fact: `P_10` (permission exists in policy)

5. **Defeasible Sufficiency**: Soft constraint for approval likelihood
   - Formula: `(P_6 ∧ P_8 ∧ P_9) ⟹ P_7`

---

## Output Statistics

- **Primitive Propositions**: 12 (P_1 through P_12)
- **Hard Constraints**: 6 (H_1 through H_6)
- **Soft Constraints**: 1 (S_1)

Generated by: **gpt-4o-mini** via OpenAI API

---

## Files Generated

### Input
```
artifacts/few_shot_examples/inputs/
└── example_03_student_assessment.txt
```

### Outputs
```
artifacts/few_shot_examples/outputs/
├── example_03_student_assessment_triples.json    # OpenIE extraction (9 triples)
├── example_03_student_assessment_llm_input.txt   # Formatted for LLM
├── example_03_student_assessment_output.json     # Full LLM output
└── example_03_for_prompt.txt                     # Formatted for prompt inclusion
```

### Runner Script
```
artifacts/few_shot_examples/
└── run_logify2_student_assessment.py
```

---

## How to Reproduce

```bash
# Set API key
export OPENAI_API_KEY='your_key_here'

# Run the full pipeline
cd /workspace/repo/artifacts/few_shot_examples
python run_logify2_student_assessment.py

# Or use logify2.py directly
cd /workspace/repo/code/from_text_to_logic
python logify2.py \
  --file /workspace/repo/artifacts/few_shot_examples/inputs/example_03_student_assessment.txt \
  --api-key "$OPENAI_API_KEY" \
  --model gpt-4o-mini \
  --output /workspace/repo/artifacts/few_shot_examples/outputs/example_03_student_assessment_output.json
```

---

## Prompt Integration

**File:** `/workspace/repo/code/prompts/prompt_logify2`

**Location:** Lines 519-669 (EXEMPLAR 3)

**Verification:**
```bash
wc -l /workspace/repo/code/prompts/prompt_logify2  # Should show 669 lines
grep -A 10 "EXEMPLAR 3" /workspace/repo/code/prompts/prompt_logify2
```

---

## Comparison with Other Examples

| Metric | Example 01 (Medical) | Example 02 (Lab Safety) | Example 03 (Student) |
|--------|---------------------|------------------------|---------------------|
| Propositions | 11 | 22 | 12 |
| Hard Constraints | 4 | 8 | 6 |
| Soft Constraints | 1 | 3 | 1 |
| Key Logic | Unless-clauses | Temporal sequences | XOR, IFF |
| Domain | Healthcare | Laboratory | Education |

---

## Educational Value

This exemplar teaches:
- How to formalize exclusive-OR (XOR) relationships
- How to distinguish biconditionals from simple implications
- How to identify necessary vs. sufficient conditions
- How to interpret modal verbs ("may", "must", "requires")
- How to handle defeasible reasoning with soft constraints

---

## Bug Fixes Applied

During this task, we identified and fixed a critical bug:

**Problem:** Code was using `format_triples()` which outputs tab-separated format, but prompt expects JSON array format.

**Solution:**
- Enhanced `openie_extractor.py` with `indent=-1` mode
- Updated `logify2.py` to use `format_triples_json(..., indent=-1)`
- Fixed label in `logic_converter.py` to "RELATION TRIPLES"

**See:** `/workspace/repo/artifacts/documentation/FORMAT_FIX_SUMMARY.md`

---

## Dependencies Required

- Python 3.11+
- Java JDK 17 (for CoreNLP)
- Stanza models (auto-downloaded)
- Stanford CoreNLP (auto-downloaded, ~508MB)
- OpenAI API key

**See:** `/workspace/repo/artifacts/documentation/DEPENDENCY_MANAGEMENT_AND_FIXES.md` for long-term solutions (Docker, etc.)

---

## Date Created

2026-01-25

---

## Related Documentation

- `/workspace/repo/artifacts/documentation/TASK_COMPLETE_FINAL.md` - Complete task summary
- `/workspace/repo/artifacts/documentation/FORMAT_FIX_SUMMARY.md` - Bug fix details
- `/workspace/repo/artifacts/documentation/DEPENDENCY_MANAGEMENT_AND_FIXES.md` - Long-term solutions
- `/workspace/repo/artifacts/README.md` - Main artifacts directory structure

---

## Status

✅ **COMPLETED** - All files generated, prompt updated, code working correctly
